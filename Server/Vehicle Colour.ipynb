{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Import Libraries\n",
    "Import necessary libraries for model building, data loading, and preprocessing."
   ],
   "id": "52bcb2fa1d9c0638"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.api.preprocessing import image_dataset_from_directory\n",
    "from tensorflow.data import AUTOTUNE, Dataset\n",
    "from keras.api.applications import MobileNetV2\n",
    "from keras.api.applications.mobilenet_v2 import preprocess_input\n",
    "from keras.api.layers import Input, RandomRotation, RandomZoom, RandomFlip, RandomTranslation, GlobalAveragePooling2D, Dense, BatchNormalization, Dropout\n",
    "from keras.api.models import Model, load_model, save_model\n",
    "from keras.api.activations import relu, softmax\n",
    "from keras.api.regularizers import L2\n",
    "from keras.api.optimizers import Adam\n",
    "from keras.api.losses import SparseCategoricalCrossentropy\n",
    "from keras.api.metrics import SparseCategoricalAccuracy\n",
    "from numpy import ndarray, dtype, float32\n",
    "from typing import Any, Tuple, List, TypeAlias\n",
    "\n",
    "Array: TypeAlias = ndarray[Any, dtype[float32]]"
   ],
   "id": "608e7a13751c069d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Load Data\n",
    "Load training and validation datasets."
   ],
   "id": "ed75336b13c5d44d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "height: int = 224\n",
    "width: int = 224"
   ],
   "id": "17dbca56ea1df4fe",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def load_data(\n",
    "        directory: str,\n",
    "        color: str,\n",
    "        batch: int,\n",
    "        size: Tuple[int, int],\n",
    "        split: float\n",
    ") -> Tuple[Dataset, Dataset]:\n",
    "    dataset: List = image_dataset_from_directory(directory = directory, labels = \"inferred\", label_mode = \"int\", color_mode = color, batch_size = batch, image_size = size, shuffle = True, validation_split = split, subset = \"both\", seed = 42)\n",
    "\n",
    "    return dataset[0], dataset[1]"
   ],
   "id": "43c6b22326ee9c6d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "train_dataset, test_dataset = load_data(\"data/Vehicle Colour\", \"rgb\", 32, (height, width), 0.1)",
   "id": "7569e642480c1127",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Data Exploration",
   "id": "ebc9a2cb11c63ada"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Shape of Images\n",
    "Check the shape of the images and labels in the dataset."
   ],
   "id": "6d8ad809ac0b1e10"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "X_train: Array = np.array([], dtype = float32)\n",
    "y_train: Array = np.array([], dtype = float32)\n",
    "\n",
    "for images, labels in train_dataset.take(1):\n",
    "    print(f\"X_train {images.shape}\")\n",
    "    print(f\"y_train {labels.shape}\")\n",
    "\n",
    "    X_train = images[:10]\n",
    "    y_train = labels[:10].numpy()\n",
    "\n",
    "for images, labels in test_dataset.take(1):\n",
    "    print(f\"X_test  {images.shape}\")\n",
    "    print(f\"y_test  {labels.shape}\")"
   ],
   "id": "117f7284c37065e2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Display Images\n",
    "Visualize a few images from the training dataset to ensure correctness."
   ],
   "id": "2abfed6cadc3fcee"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "plt.figure(figsize = (10, 3.5))\n",
    "plt.subplots_adjust(wspace = 0.5, hspace = 0.5)\n",
    "\n",
    "for i in range(X_train.shape[0]):\n",
    "    plt.subplot(2, 5, i + 1)\n",
    "    plt.imshow(X_train[i] / 255)\n",
    "    plt.title(y_train[i])"
   ],
   "id": "f216175af1ab99ec",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Preprocess Data\n",
    "Preprocess the data using Keras `preprocess_input()` function, and then prefetch the data."
   ],
   "id": "7d06070a45559345"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "train_dataset = train_dataset.map(lambda\n",
    "        x,\n",
    "        y: (preprocess_input(x), y))\n",
    "\n",
    "test_dataset = test_dataset.map(lambda\n",
    "        x,\n",
    "        y: (preprocess_input(x), y))"
   ],
   "id": "33c00c22772b0d2c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "train_dataset = train_dataset.prefetch(buffer_size = AUTOTUNE)\n",
    "test_dataset = test_dataset.prefetch(buffer_size = AUTOTUNE)"
   ],
   "id": "ac6c02a8681f23d6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Build The Model",
   "id": "57cc695d3cf5bbaa"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Base Model (MobileNetV2)\n",
    "Use the pre-trained MobileNetV2 model without the top layers."
   ],
   "id": "7fa60bc5142abad3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "base_model: MobileNetV2 = MobileNetV2(input_shape = (height, width, 3), include_top = False, weights = \"imagenet\")",
   "id": "1a2ee5af33bea830",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "base_model.trainable = False",
   "id": "94ae289fbe17094d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "inputs = Input(shape = (height, width, 3), dtype = float32)\n",
    "\n",
    "T = RandomRotation((-0.25, 0.25), interpolation = \"nearest\")(inputs)\n",
    "T = RandomZoom(height_factor = (-0.1, 0.1), width_factor = (-0.1, 0.1), interpolation = \"nearest\")(T)\n",
    "T = RandomFlip(mode = \"horizontal_and_vertical\")(T)\n",
    "T = RandomTranslation(height_factor = (-0.1, 0.1), width_factor = (-0.1, 0.1), interpolation = \"nearest\")(T)\n",
    "T = base_model(T, training = False)\n",
    "T = GlobalAveragePooling2D()(T)\n",
    "T = Dense(units = 64, activation = relu, kernel_regularizer = L2(0.01))(T)\n",
    "T = BatchNormalization()(T)\n",
    "T = Dropout(rate = 0.3)(T)\n",
    "\n",
    "outputs = Dense(units = 3, activation = softmax)(T)\n",
    "\n",
    "model: Model = Model(inputs, outputs)"
   ],
   "id": "15ea192f0a1f2487",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "model.compile(optimizer = Adam(learning_rate = 0.001), loss = SparseCategoricalCrossentropy(), metrics = [SparseCategoricalAccuracy()])",
   "id": "2fdf664fd718a4cc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Initial Training\n",
    "Train the model with the pre-trained base model frozen."
   ],
   "id": "efca1118f7fc3fe9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "model.fit(train_dataset, epochs = 1, validation_data = test_dataset)",
   "id": "b8bb7cb302d3a4b6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Fine-Tuning\n",
    "Unfreeze the base model for fine-tuning."
   ],
   "id": "159d4a9ada9ea4b1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "base_model.trainable = True",
   "id": "bafc36a21a3f96ea",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "model.compile(optimizer = Adam(learning_rate = 0.00001), loss = SparseCategoricalCrossentropy(), metrics = [SparseCategoricalAccuracy()])",
   "id": "fe97d9e175b568f2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Retrain Model\n",
    "Retrain the model with the pre-trained base model unfrozen."
   ],
   "id": "2f8d08eacb0484ce"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "model.fit(train_dataset, epochs = 1, validation_data = test_dataset)",
   "id": "1e0b1f423b24d16",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Load Model\n",
    "Load the trained model and use it."
   ],
   "id": "b3d8d61ef6db5876"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "# model: Model = load_model(\"models/Vehicle Colour.keras\")",
   "id": "3af76d6e4f88d0c6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Evaluate the Model\n",
    "Check the model's accuracy on the train and test sets."
   ],
   "id": "cc47af12e1090443"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(model.evaluate(train_dataset))\n",
    "print(model.evaluate(test_dataset))"
   ],
   "id": "b8e74885ce7740d2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Save the Model\n",
    "Save the trained model for future use."
   ],
   "id": "5b25f3ece2382af1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "save_model(model = model, filepath = \"models/Vehicle Colour.keras\", zipped = True, overwrite = True)",
   "id": "a6bf7eaacfff67bd",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
